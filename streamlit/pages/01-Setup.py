import streamlit as st

st.markdown('''
## Setup

1. Clone this repository

```shell
git clone git@github.com:vertocode/kobe-shot-model.git
```

2. Set up the virtual environment

First, let’s create a virtual environment. I will use pyenv, but feel free to use any other tool you prefer.

```shell
pyenv virtualenv 3.11.6 shotmodel
```

> If you encounter the error: pyenv: no such command 'virtualenv', you need to install pyenv-virtualenv. To install it on macOS, run: `brew install pyenv-virtualenv`

I used the name “shotmodel” for the environment, but you can choose any name you prefer.

Make sure you have created the environment using Python 3.11.6.

Now, activate the newly created virtual environment by running the following command:

```shell
pyenv activate shotmodel
```

> Note: The command may vary depending on the name you chose for your virtual environment.

> Note 2: If you receive the error: 
> 
> Failed to activate virtualenv.
> 
> Perhaps pyenv-virtualenv has not been loaded into your shell properly.
> Please restart current shell and try again.
> 
> You can resolve running the commands below:
> ```shell
> eval "$(pyenv init --path)"
> eval "$(pyenv init -)" && pyenv rehash
> ```


3. Install dependencies

```shell
pip install -r requirements.txt
```

4. Run MLFlow

```shell
mlflow server
```

5. Run kedro

Open another terminal, enter in the same virtual environment, and run the following command:

```shell
python -m kedro run
```

6. Serve the model as an API using MLFlow

If you open http://127.0.0.1:5000/ in your browser and go to the “Experiments” tab, then click on the “kedro_ml” experiment in the sidebar (which was generated by running kedro run), you’ll see a list of experiment runs.

Open the first experiment in the list — there you’ll find the “Experiment ID”. Copy this ID and use it in the following command to serve the best model as an API, which can then be consumed in your Streamlit app.


```shell
mlflow models serve -m runs:/<run_id>/model -p 5050
```

7. Run streamlit

```shell
streamlit run streamlit/main.py
```

At this point, you have the trained model, the MLflow dashboard up and running, the model served as an API via MLflow, and the Streamlit interface fully operational!

![streamlit.png](images/streamlit-default.png)


''')